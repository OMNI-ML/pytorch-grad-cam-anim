@inproceedings{eigencam,
  title={Eigen-cam: Class activation map using principal components},
  author={Muhammad, Mohammed Bany and Yeasin, Mohammed},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--7},
  year={2020},
  organization={IEEE}
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@article{simonyan2013deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
}

@article{springenberg2014striving,
  title={Striving for simplicity: The all convolutional net},
  author={Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1412.6806},
  year={2014}
}

@inproceedings{mahendran2016salient,
  title={Salient deconvolutional networks},
  author={Mahendran, Aravindh and Vedaldi, Andrea},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part VI 14},
  pages={120--135},
  year={2016},
  organization={Springer}
}

@inproceedings{gradcam,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International conference on machine learning},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}

@inproceedings{gradcampp,
  title={Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks},
  author={Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N},
  booktitle={2018 IEEE winter conference on applications of computer vision (WACV)},
  pages={839--847},
  year={2018},
  organization={IEEE}
}

@article{zhou2014object,
  title={Object detectors emerge in deep scene cnns},
  author={Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  journal={arXiv preprint arXiv:1412.6856},
  year={2014}
}

@article{lipton2018mythos,
  title={The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery.},
  author={Lipton, Zachary C},
  journal={Queue},
  volume={16},
  number={3},
  pages={31--57},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@article{adebayo2018sanity,
  title={Sanity checks for saliency maps},
  author={Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{kindermans2019reliability,
  title={The (un) reliability of saliency methods},
  author={Kindermans, Pieter-Jan and Hooker, Sara and Adebayo, Julius and Alber, Maximilian and Sch{\"u}tt, Kristof T and D{\"a}hne, Sven and Erhan, Dumitru and Kim, Been},
  journal={Explainable AI: Interpreting, explaining and visualizing deep learning},
  pages={267--280},
  year={2019},
  publisher={Springer}
}

@article{morcos2018importance,
  title={On the importance of single directions for generalization},
  author={Morcos, Ari S and Barrett, David GT and Rabinowitz, Neil C and Botvinick, Matthew},
  journal={arXiv preprint arXiv:1803.06959},
  year={2018}
}

@article{zhou2018revisiting,
  title={Revisiting the importance of individual units in cnns via ablation},
  author={Zhou, Bolei and Sun, Yiyou and Bau, David and Torralba, Antonio},
  journal={arXiv preprint arXiv:1806.02891},
  year={2018}
}


@INPROCEEDINGS {Zhou16,
author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Learning Deep Features for Discriminative Localization},
year = {2016},
volume = {},
issn = {1063-6919},
pages = {2921-2929},
abstract = {In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on imagelevel labels. While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on an image. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1\% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation. We demonstrate in a variety of experiments that our network is able to localize the discriminative image regions despite just being trained for solving classification task1.},
keywords = {visualization;neural networks;training;object recognition;computer vision;detectors;spatial resolution},
doi = {10.1109/CVPR.2016.319},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2016.319},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}

@article{Jiang21,
  title={LayerCAM: Exploring Hierarchical Class Activation Maps For Localization},
  author={Jiang, Peng-Tao and Zhang, Chang-Bin and Hou, Qibin and Cheng, Ming-Ming and Wei, Yunchao},
  journal={IEEE Transactions on Image Processing},
  year={2021},
  publisher={IEEE}
}


@inproceedings{Wang20,
  title={Score-CAM: Score-weighted visual explanations for convolutional neural networks},
  author={Wang, Haofan and Wang, Zifan and Du, Mengnan and Yang, Fan and Zhang, Zijian and Ding, Sirui and Mardziel, Piotr and Hu, Xia},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={24--25},
  year={2020}
}

@INPROCEEDINGS{Desai20, 
author={Desai, Saurabh and Ramaswamy, Harish G.},
booktitle={2020 IEEE Winter Conference on Applications of Computer Vision (WACV)},
title={Ablation-CAM: Visual Explanations for Deep Convolutional Network via Gradient-free Localization},
year={2020}, volume={}, number={},
pages={972-980},}

@misc{Fu20,
    title={Axiom-based Grad-CAM: Towards Accurate Visualization and Explanation of CNNs},
    author={Ruigang Fu and Qingyong Hu and Xiaohu Dong and Yulan Guo and Yinghui Gao and Biao Li},
    year={2020},
    eprint={2008.02312},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}


@inproceedings{Srinivas19,
    title={Full-Gradient Representation for Neural Network Visualization},
    author={Srinivas, Suraj and Fleuret, Fran√ßois},
    booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
    year={2019}
}

@misc{Draelos20,
  doi = {10.48550/ARXIV.2011.08891},
  url = {https://arxiv.org/abs/2011.08891},
  author = {Draelos, Rachel Lea and Carin, Lawrence},
  keywords = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Use HiResCAM instead of Grad-CAM for faithful explanations of convolutional neural networks},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@misc{Gildenblat21,
  title={PyTorch library for CAM methods},
  author={Jacob Gildenblat and contributors},
  year={2021},
  publisher={GitHub},
  howpublished={\url{https://github.com/jacobgil/pytorch-grad-cam}},
}

@InProceedings{Rong22,
  title     = {A Consistent and Efficient Evaluation Strategy for Attribution Methods},
  author    = {Rong, Yao and Leemann, Tobias and Borisov, Vadim and Kasneci, Gjergji and Kasneci, Enkelejda},
  booktitle = {Proceedings of the 39th International Conference on Machine Learning},
  pages     = {18770--18795},
  year      = {2022},
  publisher = {PMLR}
}