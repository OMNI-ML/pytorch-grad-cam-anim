{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVLE97nslph7"
      },
      "source": [
        "# Animating End-to-End Network Actication Maps\n",
        "\n",
        "Authors: Emily Kaczmarek, Olivier Miguel, Kevin Dick\n",
        "\n",
        "---\n",
        "\n",
        "#### Resources:\n",
        "* GitHub repo to push our changes to: https://github.com/jacobgil/pytorch-grad-cam\n",
        "* Command for ffmpeg: `ffmpeg -framerate 5 -pattern_type glob -i \"*.png\" -c:v libx264 -r 30 -vf \"scale=1200:-2,format=yuv420p\" -movflags +faststart output.mp4`\n",
        "\n",
        "TODO: write fancy things here\n",
        "\n",
        "#### Hackathon Day 1:\n",
        "* Determine a few example benchmark image datasets that we demo\n",
        "  * MNIST\n",
        "  * whatever GradCAM paper used\n",
        "  * Anotherrrrr\n",
        "* Determine what pre-trained model architecture we use:\n",
        " * DenseNet (no isses in layer name\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avy6xv6_lv5G"
      },
      "source": [
        "## Package setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -version"
      ],
      "metadata": {
        "id": "XG8DDHjaJP2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls\n",
        "!git clone https://github.com/OMNI-ML/pytorch-grad-cam-anim.git\n",
        "!ls\n",
        "\n",
        "# the % command makes the cd last beyond this cell / line\n",
        "%cd pytorch-grad-cam-anim\n",
        "!ls\n",
        "!git checkout adapt-basecam-to-support-cam_anim"
      ],
      "metadata": {
        "id": "DUNMPT_WI5-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git log --oneline --max-count=10 # --reverse"
      ],
      "metadata": {
        "id": "E2hAkgyhInev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUIsrBJncYx7"
      },
      "outputs": [],
      "source": [
        "# !python setup.py install - avoid this\n",
        "!pip install .\n",
        "!pip install -r requirements_CAManim.txt\n",
        "!pip install ffmpeg-python\n",
        "!pip install memory_profiler\n",
        "%load_ext memory_profiler\n",
        "\n",
        "!pip install \"monai[fire]\" \"torch\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR1lmtLVl0De"
      },
      "source": [
        "## Load image/data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import requests\n",
        "from pytorch_grad_cam.utils.image import preprocess_image\n",
        "from tqdm import tqdm\n",
        "import torch"
      ],
      "metadata": {
        "id": "TZ9WABEOiIN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bear image"
      ],
      "metadata": {
        "id": "vM_IvUluiI0i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13bKPUQbjqFv"
      },
      "outputs": [],
      "source": [
        "image_url = \"https://th.bing.com/th/id/R.94b33a074b9ceeb27b1c7fba0f66db74?rik=wN27mvigyFlXGg&riu=http%3a%2f%2fimages5.fanpop.com%2fimage%2fphotos%2f31400000%2fBear-Wallpaper-bears-31446777-1600-1200.jpg&ehk=oD0JPpRVTZZ6yizZtGQtnsBGK2pAap2xv3sU3A4bIMc%3d&risl=&pid=ImgRaw&r=0\"\n",
        "img = np.array(Image.open(requests.get(image_url, stream=True).raw))\n",
        "img = cv2.resize(img, (224, 224))\n",
        "img = np.float32(img) / 255\n",
        "input_tensor = preprocess_image(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "input_tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "breast image"
      ],
      "metadata": {
        "id": "-IvmB5OthrdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_pth = \"/content/bundles/breast_density_classification/sample_data/A/sample_A1.jpg\"\n",
        "img = np.array(Image.open(image_pth))\n",
        "img = cv2.resize(img, (299, 299))\n",
        "print(np.max(img))\n",
        "print(np.min(img))\n",
        "# img = np.float32(img) / np.max(img)\n",
        "input_tensor = preprocess_image(img)#, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "print(input_tensor.min())\n",
        "print(input_tensor.max())\n",
        "input_tensor.shape"
      ],
      "metadata": {
        "id": "pkOOQVbchrKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQUxmCDHl4o-"
      },
      "source": [
        "## Define CAM list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9wmDAABm0UC"
      },
      "outputs": [],
      "source": [
        "# from pytorch_grad_cam import GradCAM, GradCAMPlusPlus, EigenGradCAM, AblationCAM, RandomCAM\n",
        "from pytorch_grad_cam import EigenCAM, \\\n",
        "                              EigenGradCAM, \\\n",
        "                              FullGrad, \\\n",
        "                              GradCAM, \\\n",
        "                              GradCAMElementWise, \\\n",
        "                              GradCAMPlusPlus, \\\n",
        "                              HiResCAM, \\\n",
        "                              LayerCAM, \\\n",
        "                              RandomCAM, \\\n",
        "                              ScoreCAM, \\\n",
        "                              XGradCAM, \\\n",
        "                              AblationCAM\n",
        "\n",
        "\n",
        "cams_list = [#'AblationCAM', # ran out of RAM\n",
        "            'GradCAM',\n",
        "            # 'HiResCAM',\n",
        "            # 'GradCAMElementWise',\n",
        "            # 'GradCAMPlusPlus',\n",
        "            # 'EigenCAM', # done\n",
        "            # #'EigenGradCAM', # Skipped all layers for AlexNet; figure out\n",
        "            # 'RandomCAM',\n",
        "            # 'LayerCAM',\n",
        "            #  'XGradCAM',\n",
        "             #'FullGrad', # Skipped all layers for DenseNet161; figure out\n",
        "             #'ScoreCAM', # ran out of RAM\n",
        "             ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPQohOAOqSTJ"
      },
      "source": [
        "## Define google drive location"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We connect google drive to save the generated CAManim picutres and videos. The root of the save directory is defined by the variable `save_root`"
      ],
      "metadata": {
        "id": "qSY1MJHD2d6r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NdStPjwpT_Q"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "# drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "drive.mount(\"/content/gdrive\")\n",
        "drive_path = '/content/gdrive/MyDrive'\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "save_root = Path(drive_path) / \"starCAManim\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Models"
      ],
      "metadata": {
        "id": "lRsm3DowHGN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "breast density model"
      ],
      "metadata": {
        "id": "tGb2L3GWheSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m monai.bundle download \"breast_density_classification\" --bundle_dir \"../bundles/\""
      ],
      "metadata": {
        "id": "HWmGLFtmI0MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load monai breast density model\n",
        "from monai.networks.nets import TorchVisionFCModel\n",
        "model_path = \"/content/bundles/breast_density_classification/models/model.pt\"\n",
        "breast_model = TorchVisionFCModel(model_name=\"inception_v3\", num_classes=4, pool=None) # ref for params -> https://github.com/Project-MONAI/model-zoo/blob/dev/models/breast_density_classification/configs/inference.json\n",
        "breast_model.load_state_dict(torch.load(model_path))\n",
        "breast_model.eval()"
      ],
      "metadata": {
        "id": "IhocC2s_f7Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torchvision pretrained model"
      ],
      "metadata": {
        "id": "4Ru8yAZ6hiYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models # Only needed for example model, not overall anim code\n",
        "# model = models.densenet161(pretrained=True)# List available models\n",
        "all_models = models.list_models()\n",
        "classification_models = models.list_models(module=models)\n",
        "classification_models"
      ],
      "metadata": {
        "id": "3iS5gHBrkx2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: ViT\n",
        "\n",
        "https://github.com/jacobgil/pytorch-grad-cam/blob/master/usage_examples/vit_example.py#L65C1-L65C1\n",
        "\n"
      ],
      "metadata": {
        "id": "7Lakw2BRORst"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_scxPvUl9-z"
      },
      "source": [
        "## Define models dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t0Kd2XQiGus"
      },
      "outputs": [],
      "source": [
        "models_dict = {\n",
        "                # \"wide_resnet101_2\": models.wide_resnet101_2(pretrained=True),\n",
        "                # \"resnet18\": models.resnet18(pretrained=True),\n",
        "                # \"densenet121\": models.densenet161(pretrained=True),\n",
        "                \"breast_density_classification\": breast_model\n",
        "              }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### visualize model parameters\n"
      ],
      "metadata": {
        "id": "bwZCYJWIHI7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_key = list(models_dict.keys())[0] # pick first model in dictionary\n",
        "print(model_key)\n",
        "\n",
        "model = models_dict[model_key]\n",
        "layers = [layer for layer, what_is_this in model.named_modules()]\n",
        "print(len(layers))\n",
        "parameters = [p for p in model.parameters()]# if p.requires_grad]\n",
        "len(parameters)"
      ],
      "metadata": {
        "id": "N2rxAMTnqMNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "running_sum = 0\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "for layer_name, layer_module in model.named_modules():\n",
        "\n",
        "  # print(\"-\"*6 + layer_name + \"-\"*6)\n",
        "  # print(type(layer_name))\n",
        "  # print(type(layer_module))\n",
        "  # layer_parameters = [parameters = [p for p in model.parameters()]# if p.requires_grad]]\n",
        "  n_layer_params = sum(p.numel() for p in layer_module.parameters() if p.requires_grad)\n",
        "  running_sum += n_layer_params\n",
        "\n",
        "print(running_sum)\n",
        "print(total_params)"
      ],
      "metadata": {
        "id": "-Z3-Tep-rIq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhv9bcMKmYj9"
      },
      "source": [
        "## Loop Generate CAManim\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### utils"
      ],
      "metadata": {
        "id": "h6TQidjwL6Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_target_layers(model):\n",
        "  \"\"\"\n",
        "  target_layers doesn't matter for cam_anim (since we loop through all the layers),\n",
        "  but it is needed for initializing the GradCAM object.\n",
        "  This method returns the last layer (that is viable as a target i.e. iterable) of the model.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  target_layers = []\n",
        "  for _, layer_module in model.named_modules():\n",
        "    # print(_)\n",
        "    if _ == \"features.Mixed_7c.branch_pool.conv\":\n",
        "      target_layers.append(layer_module)\n",
        "    # https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable\n",
        "    try:\n",
        "      some_object_iterator = iter(layer_module)\n",
        "      if type(layer_module)!=str:\n",
        "        target_layers.append(layer_module)\n",
        "\n",
        "    except TypeError as te:\n",
        "      pass\n",
        "      # print(some_object, 'is not iterable')\n",
        "  # target_layers = target_layers[-2]\n",
        "  print(target_layers[-1])\n",
        "  return [target_layers[-1]]"
      ],
      "metadata": {
        "id": "dlIEv4h9AWZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_grad_cam.base_cam import BaseCAM\n",
        "import pandas as pd\n",
        "\n",
        "import gc\n",
        "gc.enable()\n",
        "\n",
        "print(gc.collect())\n",
        "print(pd.DataFrame.from_records(gc.get_stats()))"
      ],
      "metadata": {
        "id": "eH8OG4pXJK1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Double Loop - n_models X n_cams"
      ],
      "metadata": {
        "id": "XSDkmxOkJdav"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XpYgO_rmn7p"
      },
      "outputs": [],
      "source": [
        "n_models = len(models_dict.keys())\n",
        "n_cams = len(cams_list)\n",
        "\n",
        "print(f\"{n_models} X {n_cams} = {n_models*n_cams} iterations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx2bR-8Cegv-"
      },
      "outputs": [],
      "source": [
        "# %%mprun -f BaseCAM.cam_anim\n",
        "\n",
        "metrics_records = []\n",
        "for model_name, model in models_dict.items():\n",
        "\n",
        "  print(\"=\"*33 + model_name + \"=\"*33)\n",
        "\n",
        "  outdir = Path(drive_path) / \"starCAManim\" / model_name\n",
        "  outdir.mkdir(exist_ok=True, parents= True)\n",
        "\n",
        "  target_layers = get_target_layers(model)\n",
        "  # target_layers = [\"features.Mixed_7c.branch_pool.conv\"]\n",
        "\n",
        "  for cam_name in cams_list:\n",
        "    print(\"-\"*33 + cam_name + \"-\"*33)\n",
        "\n",
        "    frames_dir = outdir / cam_name\n",
        "    frames_dir.mkdir(exist_ok=True, parents= True)\n",
        "    metrics = {\"model_name\": model_name, \"CAM Name\": cam_name, \"error\": None}\n",
        "    try:\n",
        "      cam = globals()[cam_name](model=model, target_layers=target_layers, use_cuda=False)\n",
        "      metrics_update = cam.cam_anim(img,\n",
        "                                    input_tensor,\n",
        "                                    frame_rate=24,\n",
        "                                    norm_type='both',\n",
        "                                    keep_frames=True,\n",
        "                                    tmp_dir=str(frames_dir),\n",
        "                                    output_fname=str(outdir / f\"{cam_name}_anim.mp4\"))\n",
        "\n",
        "      metrics.update(metrics_update)\n",
        "      del cam\n",
        "      gc.collect()\n",
        "      print(pd.DataFrame.from_records(gc.get_stats()))\n",
        "      print(f\"{cam_name} Finished\")\n",
        "\n",
        "\n",
        "    except Exception as ex:\n",
        "      metrics.update({\"error\": str(ex)})\n",
        "      print(ex)\n",
        "      print(\"Continuing to the next CAM\")\n",
        "      raise ex\n",
        "\n",
        "    metrics_records.append(metrics)\n",
        "\n",
        "    with open(str(Path(drive_path) / \"starCAManim\" / f\"metrics_logs_{model_name}.json\"), \"w\") as outfile:\n",
        "      json.dump(metrics_records, outfile, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO: Triple Loop - n_models x n_cams x n_images"
      ],
      "metadata": {
        "id": "Ks_kpNA5Jzrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: write a triple loop enable multiple images.\n",
        "# N.B. models can be paired with a dataset. Use a dictionary to map models to dataset or vice-versa"
      ],
      "metadata": {
        "id": "TGbLEOUSJ7f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Videos Only\n",
        "\n",
        "Run this section if you have all the frames and want to regenerate the video"
      ],
      "metadata": {
        "id": "uozRGm7rPHy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "def _ffmpeg_standard_quality(tmp_path, output_fname, frame_rate=5):\n",
        "  \"\"\" _ffmpeg_standard_quality\n",
        "      Generates and saves-to-file the animated .MP4 video in standard quality.\n",
        "      ---\n",
        "      Input: tmp_path <str>, the path to the images\n",
        "             output_fname <str>, the path and filename for the saved file\n",
        "             frame_rate=5 <int>, the number of frames per second\n",
        "      Output: None\n",
        "  \"\"\"\n",
        "  print('Generating video with pngs from:\\n', tmp_path)\n",
        "  try:\n",
        "    # Define the command\n",
        "    command = ['ffmpeg', '-framerate', str(frame_rate), '-pattern_type', 'glob', '-i', tmp_path + '/*.png', '-c:v', 'libx264', '-pix_fmt', 'yuv420p', output_fname]\n",
        "\n",
        "    # Run the command and capture all output channels\n",
        "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
        "\n",
        "    # Print the output\n",
        "    print(result.stdout)\n",
        "    print(result.stderr)\n",
        "  except Exception as exc:\n",
        "    print('ERROR: ffmpeg video generation failed; video corrupt.')\n",
        "    print(exc)\n",
        "  return None"
      ],
      "metadata": {
        "id": "jI34ZYYF0WVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_records = []\n",
        "for model_name, model in models_dict.items():\n",
        "\n",
        "  print(\"=\"*33 + model_name + \"=\"*33)\n",
        "\n",
        "  outdir = Path(drive_path) / \"starCAManim\" / model_name\n",
        "  outdir.mkdir(exist_ok=True, parents= True)\n",
        "\n",
        "  # target_layers = get_target_layers(model)\n",
        "  # target_layers = [\"features.Mixed_7c.branch_pool.conv\"]\n",
        "\n",
        "  for cam_name in cams_list:\n",
        "    print(\"-\"*33 + cam_name + \"-\"*33)\n",
        "\n",
        "    frames_dir = outdir / cam_name\n",
        "    frames_dir.mkdir(exist_ok=True, parents= True)\n",
        "    metrics = {\"model_name\": model_name, \"CAM Name\": cam_name, \"error\": None}\n",
        "    for norm_type in [\"global\", \"layer\"]:\n",
        "      tmp_path = str(outdir / cam_name / norm_type)\n",
        "      output_fname = str(outdir / f\"{cam_name}_{norm_type}_anim.mp4\")\n",
        "      # !ffmpeg -framerate 24 -pattern_type glob -i '<tmp_path>/*.png' -c:v libx264 -pix_fmt yuv420p $output_fname\n",
        "      _ffmpeg_standard_quality(tmp_path, output_fname, frame_rate=24)"
      ],
      "metadata": {
        "id": "lXt-mcvqYh0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load logged metrics"
      ],
      "metadata": {
        "id": "z6e6ebENG49E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Opening JSON file\n",
        "model_name = \"breast_density_classification\"\n",
        "with open(str(Path(drive_path) / \"starCAManim\" / f\"metrics_logs_{model_name}.json\"), 'r') as openfile:\n",
        "    # Reading from json file\n",
        "    metrics_records = json.load(openfile)"
      ],
      "metadata": {
        "id": "XkXks9tzSTWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "metrics_df = pd.DataFrame.from_records(metrics_records)\n",
        "display(metrics_df)"
      ],
      "metadata": {
        "id": "85NxTkHDPybg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unpack_layer_records(row):\n",
        "\n",
        "  layer_df = pd.DataFrame.from_records(row[\"layers_records\"])\n",
        "\n",
        "  for col in row.index:\n",
        "    if col not in [\"layers_records\", \"error\"]:\n",
        "      layer_df[col] = row[col]\n",
        "\n",
        "    layer_df[\"cam_anim_error\"] = row[\"error\"]\n",
        "\n",
        "  return layer_df\n"
      ],
      "metadata": {
        "id": "ecP_pFWRen5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "  'date': ['2022-09-14', '2022-09-15', '2022-09-16'],\n",
        "  'letter': ['A', 'B', 'C'],\n",
        "  'dict' : [{ 'fruit': 'apple', 'weather': 'aces'},\n",
        "            { 'fruit': 'banana', 'weather': 'bad'},\n",
        "            { 'fruit': 'cantaloupe', 'weather': 'cloudy'}],\n",
        "})\n",
        "\n",
        "pd.concat([df.drop(['dict'], axis=1), df['dict'].apply(pd.Series)], axis=1)"
      ],
      "metadata": {
        "id": "OTyMaUivPOW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_metrics_df = None\n",
        "\n",
        "for _, row in metrics_df.iterrows():\n",
        "  layer_df = unpack_layer_records(row)\n",
        "\n",
        "  if layer_metrics_df is None:\n",
        "    layer_metrics_df = layer_df\n",
        "  else:\n",
        "    layer_metrics_df = pd.concat([layer_metrics_df, layer_df])\n",
        "\n",
        "\n",
        "display(layer_metrics_df)\n",
        "# layer_metrics_df = layer_metrics_df.groupby(\"CAM Name\")\n",
        "layer_metrics_df[\"layer_time\"].describe()"
      ],
      "metadata": {
        "id": "aF9qGQjNZPLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot"
      ],
      "metadata": {
        "id": "UMXDyjyrG_rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "import pandas as pd\n",
        "\n",
        "df = layer_metrics_df.copy(deep=True)\n",
        "# df = df[df[\"CAM Name\"]==\"HiResCAM\"]\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.scatterplot(x=\"layer_num_parameters\", y=\"layer_time\",\n",
        "                # s=100,\n",
        "                # figsize=(64,64),\n",
        "                hue='CAM Name',\n",
        "                #style='zone_number',\n",
        "                data=df)\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i-EamQlW0jTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rISgJQCBJIe8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}